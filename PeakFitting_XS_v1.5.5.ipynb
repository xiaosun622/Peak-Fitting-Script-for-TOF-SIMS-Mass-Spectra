{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "968690f2",
      "cell_type": "markdown",
      "source": "# Interactive Peak Fitting Tool for FIB TOF-SIMS / Mass Spectra\n\n## Overview\n\nThis Jupyter Notebook-based tool is designed for interactive peak fitting of FIB TOF-SIMS and other mass spectrometry data. It supports Gaussian, Lorentzian, and PseudoVoigt models with optional baseline correction, smoothing, and default settings on uranium isotope ratio analysis.\n\n**Current Version:** 1.5.4\n\n**Author:** Xiao Sun [https://github.com/xiaosun622]\n\n---\n\n## Workflow: Step-by-Step Procedure\n\n### 1. Load Spectrum File\n\n* Reads a tab-delimited `.txt` file.\n* Expected columns:\n\n  * `mass/charge (m/Q)` (x-axis)\n  * `Total (cts/TOF-Extraction)` (intensity)\n\n### 2. Apply Smoothing (Optional)\n\n* Savitzky–Golay smoothing filter reduces noise while preserving peak shape.\n* Adjustable parameters:\n\n  * `Smooth Win`: Window size\n  * `Polyorder`: Polynomial order used in smoothing\n\n### 3. Define Peak Regions\n\n* User inputs peak center and range width (±) for each ion.\n* Regions are defined as: `center ± range_width`\n\n### 4. Baseline Correction (if enabled)\n\n* Options:\n\n  * `average`: Flat baseline using predicted intensity ± offset\n  * `linear`: Line fit to surrounding regions\n  * `polynomial`: 2nd-order polynomial fit\n* This background is subtracted from the signal to isolate the peak.\n\n### 5. Select Fit Model\n\n* Choose between symmetric or asymmetric peak shapes:\n\n  * Gaussian\n  * Lorentzian\n  * PseudoVoigt (or Voigt for asymmetric cases)\n\n### 6. Fit the Peak\n\n* The fitting is applied to the **baseline-corrected signal**.\n* Initial parameters are estimated (center, amplitude, sigma).\n* The model is optimized to minimize the squared difference between corrected data and prediction.\n\n### 7. Extract Results\n\n* From the fit result:\n\n  * Best-fit curve (`model_prediction`)\n  * Fitting Deviation (`data - prediction`)\n  * R² (goodness of fit)\n  * Area (peak amplitude)\n\n### 8. Plot Outputs\n\nEach subplot includes:\n\n* Smoothed signal\n* Corrected signal\n* Model fit\n* **Fitting Deviation** (formerly “Residuals”)\n\n### 9. Calculate Isotope Ratios\n\nFor isotope pairs (e.g. 235U vs 238U), the ratio is:\n\n```math\n\\text{Ratio} = \\frac{\\text{Area}_{235}}{\\text{Area}_{235} + \\text{Area}_{238}}\n```\n\n### 10. Save Outputs (Manual Trigger)\n\n* Press \"Save Results\" after fitting to export:\n\n  * A PNG image of all plots\n  * A CSV summary table with areas, R², and isotope ratios\n\n---\n\n## Terminology\n\n| Term                  | Meaning                                                         |\n| --------------------- | --------------------------------------------------------------- |\n| **Fitting Deviation** | Difference between corrected data and model fit                 |\n| **Baseline**          | Estimated background under the peak (subtracted before fitting) |\n| **Best Fit**          | Model prediction using optimized parameters                     |\n| **R²**                | Coefficient of determination; closer to 1 means better fit      |\n\n---\n\n## Requirements\n\n* Python 3.7+\n* `pandas`, `numpy`, `matplotlib`, `scipy`, `lmfit`, `ipywidgets`\n\nInstall via pip:\n\n```bash\npip install pandas numpy matplotlib scipy lmfit ipywidgets\n```\n\n---",
      "metadata": {}
    },
    {
      "id": "c1896106",
      "cell_type": "markdown",
      "source": "MIT License\n\nCopyright (c) 2025 xiaosun622\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
      "metadata": {}
    },
    {
      "id": "6fe64703-0814-46e2-a609-e78259ea986a",
      "cell_type": "code",
      "source": "%pip install pandas numpy matplotlib scipy lmfit ipywidgets",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "5f1aa108-ba0b-4948-a7cd-f7be9a50a827",
      "cell_type": "code",
      "source": "# === Interactive Peak Fitting Script for TOF-SIMS / Mass Spectra ===\n\"\"\"\nTitle: Interactive Peak Fitting Tool\nAuthor: Xiao Sun [https://github.com/xiaosun622]\nVersion: 1.5.4\nDate: 15-06-2025\n\nDescription:\nInteractive Jupyter Notebook tool for peak fitting in TOF-SIMS/mass spectrometry data.\nSupports Gaussian, Lorentzian, and PseudoVoigt fits with customizable symmetric/asymmetric options,\nbaseline correction, and smoothing.\nNow includes button-controlled saving of figure and summary table based on the raw data filename.\nMade script compatible with VS Code, venv environments, ipywidgets installed.\nNow supports user-uploaded .txt spectrum files for fitting.\n\"\"\"\n\n# === [IMPORTS] ===\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import savgol_filter\nfrom scipy.integrate import trapezoid\nfrom lmfit.models import GaussianModel, LorentzianModel, PseudoVoigtModel, VoigtModel\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nimport warnings\nimport os\nimport io\n\ntry:\n    from lmfit.models import SkewedGaussianModel\nexcept ImportError:\n    SkewedGaussianModel = None\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"uncertainties.core\")\n\n# === [DATA INIT] ===\nx_column = 'mass/charge (m/Q)'\ny_column = 'Total (cts/TOF-Extraction)'\ntxt_file = None\nx = y = data = None\n\nupload_widget = widgets.FileUpload(\n    accept='.txt', multiple=False, description='Upload .txt File',\n    layout=widgets.Layout(width='300px')\n)\n\n# === [WIDGET SETUP] ===\nfit_model = widgets.Dropdown(options=['gaussian', 'lorentzian', 'pseudovoigt'], value='lorentzian', description='Fit Model:')\nsymmetric_fit = widgets.Checkbox(value=True, description='Symmetric Peak')\nuse_baseline = widgets.Checkbox(value=True, description='Baseline Correction')\nbaseline_type = widgets.Dropdown(options=['average', 'linear', 'polynomial'], value='linear')\nsmoothing_window = widgets.IntSlider(value=11, min=3, max=51, step=2, description='Smooth Win:', layout=widgets.Layout(width='300px'))\nsmoothing_poly = widgets.IntSlider(value=3, min=1, max=5, step=1, description='Polyorder:', layout=widgets.Layout(width='250px'))\n\nregion_labels = ['235U', '238U', '235UO', '238UO', '235UO2', '238UO2']\npeak_centers = {'235U': 235.0, '238U': 238.0, '235UO': 251.0, '238UO': 254.0, '235UO2': 267.0, '238UO2': 270.0}\nrange_width_widgets = {}\nbaseline_offset_widgets = {}\n\nfor label in region_labels:\n    center_widget = widgets.FloatText(value=peak_centers[label], description=f'{label}:', layout=widgets.Layout(width='150px', margin='0 10px 0 0'), step=0.1, format='%.1f')\n    width_widget = widgets.FloatText(value=1.0, description=\"Peak range: ±\", layout=widgets.Layout(width='140px', margin='0 10px 0 0'), step=0.1, format='%.1f')\n    offset_widget = widgets.FloatText(value=1.0, description=\"Baseline: ±\", layout=widgets.Layout(width='140px', margin='0 10px 0 0'), step=0.05, format='%.1f')\n    range_width_widgets[label] = (center_widget, width_widget)\n    baseline_offset_widgets[label] = offset_widget\n\nfit_button = widgets.Button(description=\"Fit and Calculate Ratios\", layout=widgets.Layout(width='300px', height='30px'))\nsave_button = widgets.Button(description=\"Save Results\", layout=widgets.Layout(width='200px', height='30px'))\n\nui = widgets.VBox([\n    upload_widget,\n    widgets.HBox([fit_model, symmetric_fit, use_baseline, baseline_type]),\n    widgets.HBox([smoothing_window, smoothing_poly]),\n    widgets.HTML(\"<b>Edit Peak Centers and Ranges</b><br><i>Baseline estimated from model at center ± baseline m/z offset</i>\"),\n    *[widgets.HBox([range_width_widgets[label][0], range_width_widgets[label][1], baseline_offset_widgets[label]]) for label in region_labels],\n    widgets.HBox([fit_button, save_button])\n])\n\nfig = None\ndf_summary = None\n\ndef get_model(model_type, symmetric=True):\n    if model_type == 'gaussian':\n        return GaussianModel() if symmetric else (SkewedGaussianModel() if SkewedGaussianModel else GaussianModel())\n    elif model_type == 'lorentzian':\n        return LorentzianModel() if symmetric else VoigtModel()\n    elif model_type == 'pseudovoigt':\n        return PseudoVoigtModel() if symmetric else VoigtModel()\n    else:\n        raise ValueError(\"Unsupported model type\")\n\ndef fit_peak_custom_baseline(x_all, y_all, model_type, mz_range, baseline_offset, symmetric, use_baseline, baseline_mode):\n    mask_peak = (x_all >= mz_range[0]) & (x_all <= mz_range[1])\n    x_peak = x_all[mask_peak]\n    y_peak = y_all[mask_peak]\n\n    if len(x_peak) < 5:\n        raise ValueError(\"Peak range too narrow or no data points available.\")\n\n    model = get_model(model_type, symmetric=symmetric)\n    center_guess = (mz_range[0] + mz_range[1]) / 2\n    height_guess = np.max(y_peak)\n    sigma_guess = (mz_range[1] - mz_range[0]) / 4\n    amplitude_guess = height_guess * sigma_guess * np.sqrt(2 * np.pi)\n    params = model.make_params(center=center_guess, amplitude=amplitude_guess, sigma=sigma_guess)\n\n    initial_result = model.fit(y_peak, params, x=x_peak)\n\n    if use_baseline:\n        if baseline_mode == 'average':\n            left_val = np.interp(center_guess - baseline_offset, x_peak, initial_result.best_fit)\n            right_val = np.interp(center_guess + baseline_offset, x_peak, initial_result.best_fit)\n            baseline = np.mean([left_val, right_val])\n            y_corr = y_peak - baseline\n        elif baseline_mode == 'linear':\n            center = (mz_range[0] + mz_range[1]) / 2\n            left_mask = (x_all >= center - baseline_offset) & (x_all < center - baseline_offset / 2)\n            right_mask = (x_all > center + baseline_offset / 2) & (x_all <= center + baseline_offset)\n            x_baseline = np.concatenate([x_all[left_mask], x_all[right_mask]])\n            y_baseline = np.concatenate([y_all[left_mask], y_all[right_mask]])\n            p = np.polyfit(x_baseline, y_baseline, deg=1)\n            baseline_line = np.polyval(p, x_peak)\n            y_corr = y_peak - baseline_line\n        elif baseline_mode == 'polynomial':\n            p = np.polyfit(x_peak, y_peak, deg=2)\n            baseline_line = np.polyval(p, x_peak)\n            y_corr = y_peak - baseline_line\n        else:\n            y_corr = y_peak\n    else:\n        y_corr = y_peak\n\n    final_result = model.fit(y_corr, model.make_params(center=center_guess, amplitude=amplitude_guess, sigma=sigma_guess), x=x_peak)\n    area = final_result.params['amplitude'].value\n    residuals = y_corr - final_result.best_fit\n    ss_res = np.sum(residuals**2)\n    ss_tot = np.sum((y_corr - np.mean(y_corr))**2)\n    r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan\n\n    return final_result, x_peak, y_peak, y_corr, area, residuals, r_squared\n\ndef run_fitting(b):\n    global df_summary, fig, x, y\n    clear_output(wait=True)\n    display(ui)\n\n    if x is None or y is None:\n        print(\"Please upload a .txt file before running fitting.\")\n        return\n\n    if smoothing_window.value >= len(y):\n        print(\"Error: Smoothing window too large for data length.\")\n        return\n\n    y_smooth = savgol_filter(y, smoothing_window.value, smoothing_poly.value)\n\n    regions = {\n        label: (\n            range_width_widgets[label][0].value - range_width_widgets[label][1].value,\n            range_width_widgets[label][0].value + range_width_widgets[label][1].value\n        )\n        for label in region_labels\n    }\n    offsets = {label: baseline_offset_widgets[label].value for label in region_labels}\n    ratio_groups = [('235U', '238U'), ('235UO', '238UO'), ('235UO2', '238UO2')]\n\n    areas = {}\n    r2_values = {}\n    results = {}\n\n    fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n    axes = axes.flatten()\n\n    for i, label in enumerate(region_labels):\n        mz_range = regions[label]\n        baseline_offset = offsets[label]\n\n        try:\n            result, x_fit, y_fit, y_corr, area, residuals, r2 = fit_peak_custom_baseline(\n                x, y_smooth, fit_model.value, mz_range, baseline_offset, symmetric_fit.value, use_baseline.value, baseline_type.value\n            )\n        except Exception as e:\n            print(f\"Error fitting {label}: {e}\")\n            continue\n\n        areas[label] = area\n        r2_values[label] = r2\n        results[label] = result\n\n        ax = axes[i]\n        ax.plot(x_fit, y_fit, label='Smoothed', color='blue')\n        if use_baseline.value:\n            ax.plot(x_fit, y_corr, label='Corrected', color='purple')\n        ax.plot(x_fit, result.best_fit, 'r--', label='Fit')\n        ax.plot(x_fit, residuals, 'k:', label='Fitting deviation')\n        ax.set_title(f\"{label} (R² = {r2:.4f})\")\n        ax.legend()\n        ax.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\n    def calc_ratio(a1, a2):\n        return a1 / (a1 + a2) if (a1 + a2) > 0 else np.nan\n\n    summary_rows = []\n    model_name = fit_model.value.capitalize()\n\n    for label in region_labels:\n        area_val = areas.get(label, np.nan)\n        summary_rows.append({\n            \"Ions\": label,\n            \"Model\": model_name,\n            \"Area\": area_val,\n            \"R²\": r2_values.get(label, np.nan),\n            \"Isotope Ratio\": \"\"\n        })\n\n    for a1, a2 in ratio_groups:\n        r = calc_ratio(areas.get(a1, 0), areas.get(a2, 0))\n        for row in summary_rows:\n            if row[\"Ions\"] == a1:\n                row[\"Isotope Ratio\"] = f\"{r:.4f}\"\n\n    df_summary = pd.DataFrame(summary_rows, columns=[\"Ions\", \"Model\", \"Area\", \"R²\", \"Isotope Ratio\"])\n    df_summary.index = np.arange(1, len(df_summary) + 1)\n    display(df_summary)\n\ndef save_results(b):\n    global df_summary, fig\n    if df_summary is None or fig is None:\n        print(\"No results to save. Please run the fitting first.\")\n        return\n    base_name = os.path.splitext(os.path.basename(txt_file))[0] if txt_file else \"output\"\n    fig.savefig(f\"{base_name}_fit.png\", dpi=300)\n    df_summary.to_csv(f\"{base_name}_summary.csv\", index=False)\n    print(f\"Saved: {base_name}_fit.png and {base_name}_summary.csv\")\n\n# === [EVENT BINDING] ===\nfit_button.on_click(run_fitting)\nsave_button.on_click(save_results)\n\n# === [UPLOAD EVENT HANDLER] ===\ndef handle_upload(change):\n    global data, x, y, txt_file\n    uploaded = upload_widget.value\n    if not uploaded:\n        print(\"No file uploaded.\")\n        return\n    file_info = list(uploaded.values())[0] if isinstance(uploaded, dict) else uploaded[0]\n    txt_file = file_info['name']\n    content = file_info['content']\n    try:\n        df = pd.read_csv(io.BytesIO(content), sep='\\t', comment='#')\n        df = df.dropna(subset=[x_column, y_column])\n        data = df\n        x = data[x_column].values\n        y = data[y_column].values\n        clear_output(wait=True)\n        display(ui)\n        print(f\"Loaded: {txt_file} | {len(data)} rows\")\n    except Exception as e:\n        print(f\"Failed to load file: {e}\")\n\nupload_widget.observe(handle_upload, names='value')\n\n# === [DISPLAY UI INITIALLY] ===\ndisplay(ui)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(FileUpload(value=(), accept='.txt', description='Upload .txt File', layout=Layout(width='300px'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1044e4108c8045518422d11e6ddeada5"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "id": "47a973a0",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}