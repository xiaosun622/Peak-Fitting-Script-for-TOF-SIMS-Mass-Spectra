{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "968690f2",
      "cell_type": "markdown",
      "source": "# Interactive Peak Fitting Tool for FIB TOF-SIMS / Mass Spectra\n\n## Overview\n\nThis Jupyter Notebook-based tool is designed for interactive peak fitting of FIB TOF-SIMS and other mass spectrometry data. It supports Gaussian, Lorentzian, and PseudoVoigt models with optional baseline correction, smoothing, and default settings on uranium isotope ratio analysis.\n\n**Current Version:** 1.5.7\n\n**Author:** Xiao Sun [https://github.com/xiaosun622]\n\n---\n\n## Workflow: Step-by-Step Procedure\n\n### 1. Load Spectrum File\n\n* Reads a tab-delimited `.txt` file.\n* Expected columns:\n\n  * `mass/charge (m/Q)` (x-axis)\n  * `Total (cts/TOF-Extraction)` (intensity)\n\n### 2. Apply Smoothing (Optional)\n\n* Savitzky–Golay smoothing filter reduces noise while preserving peak shape.\n* Adjustable parameters:\n\n  * `Smooth Win`: Window size\n  * `Polyorder`: Polynomial order used in smoothing\n\n### 3. Define Peak Regions\n\n* User inputs peak center and range width (±) for each ion.\n* Regions are defined as: `center ± range_width`\n\n### 4. Baseline Correction (if enabled)\n\n* Options:\n\n  * `average`: Flat baseline using predicted intensity ± offset\n  * `linear`: Line fit to surrounding regions\n  * `polynomial`: 2nd-order polynomial fit\n* This background is subtracted from the signal to isolate the peak.\n\n### 5. Select Fit Model\n\n* Choose between symmetric or asymmetric peak shapes:\n\n  * Gaussian\n  * Lorentzian\n  * PseudoVoigt (or Voigt for asymmetric cases)\n\n### 6. Fit the Peak\n\n* The fitting is applied to the **baseline-corrected signal**.\n* Initial parameters are estimated (center, amplitude, sigma).\n* The model is optimized to minimize the squared difference between corrected data and prediction.\n\n### 7. Extract Results\n\n* From the fit result:\n\n  * Best-fit curve (`model_prediction`)\n  * Fitting Deviation (`data - prediction`)\n  * R² (goodness of fit)\n  * Area (peak amplitude)\n\n### 8. Plot Outputs\n\nEach subplot includes:\n\n* Smoothed signal\n* Corrected signal\n* Model fit\n* **Fitting Deviation** (formerly “Residuals”)\n\n### 9. Calculate Isotope Ratios\n\nFor isotope pairs (e.g. 235U vs 238U), the ratio is:\n\n```math\n\\text{Ratio} = \\frac{\\text{Area}_{235}}{\\text{Area}_{235} + \\text{Area}_{238}}\n```\n\n### 10. Save Outputs (Manual Trigger)\n\n* Press \"Save Results\" after fitting to export:\n\n  * A PNG image of all plots\n  * A CSV summary table with areas, R², and isotope ratios\n\n---\n\n## Terminology\n\n| Term                  | Meaning                                                         |\n| --------------------- | --------------------------------------------------------------- |\n| **Fitting Deviation** | Difference between corrected data and model fit                 |\n| **Baseline**          | Estimated background under the peak (subtracted before fitting) |\n| **Best Fit**          | Model prediction using optimized parameters                     |\n| **R²**                | Coefficient of determination; closer to 1 means better fit      |\n\n---\n\n## Requirements\n\n* Python 3.7+\n* `pandas`, `numpy`, `matplotlib`, `scipy`, `lmfit`, `ipywidgets`\n\nInstall via pip:\n\n```bash\npip install pandas numpy matplotlib scipy lmfit ipywidgets\n```\n\n---",
      "metadata": {}
    },
    {
      "id": "c1896106",
      "cell_type": "markdown",
      "source": "MIT License\n\nCopyright (c) 2025 xiaosun622\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
      "metadata": {}
    },
    {
      "id": "6fe64703-0814-46e2-a609-e78259ea986a",
      "cell_type": "code",
      "source": "%pip install pandas numpy matplotlib scipy lmfit ipywidgets",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "id": "5f1aa108-ba0b-4948-a7cd-f7be9a50a827",
      "cell_type": "code",
      "source": "# === Interactive Peak Fitting Script for TOF-SIMS / Mass Spectra ===\n\"\"\"\nTitle: Interactive Peak Fitting Tool\nAuthor: Xiao Sun [https://github.com/xiaosun622]\nVersion: 1.5.7\nDate: 19-06-2025\n\nDescription:\nThis script provides an interactive Jupyter Notebook-based interface for peak fitting in TOF-SIMS or general mass spectrometry spectra.\nUsers can select fitting ranges, apply smoothing, choose fitting models (Gaussian, Lorentzian, PseudoVoigt), and toggle between symmetric/asymmetric peak models.\n\nWorkflow:\n1. Load a tab-delimited spectrum file (.txt) with mass/charge and intensity columns.\n2. Apply Savitzky–Golay smoothing to reduce noise.\n3. Define peak regions interactively via widgets (mass center and range width).\n4. For each peak:\n   - Perform an initial model fit.\n   - Estimate the baseline using fitted values ± a user-defined offset.\n   - Subtract the baseline and refit.\n   - Extract and report the amplitude (area) of the corrected fit.\n5. Plot fitted peaks and calculate isotope ratios.\n\nInteractive Options:\n- Fitting model (Gaussian, Lorentzian, PseudoVoigt)\n- Symmetric vs. asymmetric fitting\n- Smoothing window and polynomial order\n- Custom m/z center and range width for each peak\n- Use baseline correction or not\n\nSmoothing Guidelines:\n# Smooth Win: Number of data points in the window. Larger = smoother, but may distort narrow peaks. Start with 11–19.\n# Polyorder: Degree of polynomial fit in each window. Try 2 or 3 for peak preservation.\n\nFit Quality Assessment:\n# A \"good fit\" is typically indicated by a high R² value close to 1.0 (e.g., > 0.98), minimal residuals, and a visually smooth match between the fit curve and data.\n# Poor fits may result from incorrect model choice, too wide or narrow fitting windows, or baseline estimation errors.\n\"\"\"\n\n# === [IMPORTS] ===\nimport pandas as pd  # data handling\nimport numpy as np  # numerical operations\nimport matplotlib.pyplot as plt  # plotting\nfrom scipy.signal import savgol_filter  # for smoothing spectra\nfrom scipy.integrate import trapezoid  # optional integration method\nfrom lmfit.models import GaussianModel, LorentzianModel, PseudoVoigtModel, VoigtModel  # curve models\nimport ipywidgets as widgets  # interactive widgets\nfrom IPython.display import display, clear_output  # Jupyter display control\nimport warnings\nimport os\nimport io\n\n# Optional model for skewed peaks if available\ntry:\n    from lmfit.models import SkewedGaussianModel\nexcept ImportError:\n    SkewedGaussianModel = None\n\n# Suppress known user warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"uncertainties.core\")\n\n# === [DATA INIT] ===\nx_column = 'mass/charge (m/Q)'\ny_column = 'Total (cts/TOF-Extraction)'\ntxt_file = None  # name of uploaded file\nx = y = data = None  # to be populated after upload\n\n# File upload widget\nupload_widget = widgets.FileUpload(\n    accept='.txt', multiple=False, description='Upload .txt File',\n    layout=widgets.Layout(width='300px')\n)\n\n# === [WIDGET SETUP] ===\n# Fit model dropdown\nfit_model = widgets.Dropdown(options=['gaussian', 'lorentzian', 'pseudovoigt'], value='lorentzian', description='Fit Model:')\n\n# Fitting options\nsymmetric_fit = widgets.Checkbox(value=True, description='Symmetric Peak')\nuse_baseline = widgets.Checkbox(value=True, description='Baseline Correction')\nbaseline_type = widgets.Dropdown(options=['average', 'linear', 'polynomial'], value='linear')\n\n# Smoothing sliders\nsmoothing_window = widgets.IntSlider(value=11, min=3, max=51, step=2, description='Smooth Win:', layout=widgets.Layout(width='300px'))\nsmoothing_poly = widgets.IntSlider(value=3, min=1, max=5, step=1, description='Polyorder:', layout=widgets.Layout(width='250px'))\n\n# Pixel and Frames\npixel_widget = widgets.IntText(value=256, description='Pixel:', layout=widgets.Layout(width='140px'))\nframes_widget = widgets.IntText(value=200, description='Frames:', layout=widgets.Layout(width='140px'))\n\n# Define regions to analyze\nregion_labels = ['235U', '238U', '235UO', '238UO', '235UO2', '238UO2']\npeak_centers = {'235U': 235.0, '238U': 238.0, '235UO': 251.0, '238UO': 254.0, '235UO2': 267.0, '238UO2': 270.0}\nrange_width_widgets = {}\nbaseline_offset_widgets = {}\n\n# Create input widgets for each isotope region\nfor label in region_labels:\n    center_widget = widgets.FloatText(value=peak_centers[label], description=f'{label}:', layout=widgets.Layout(width='150px', margin='0 10px 0 0'), step=0.1, format='%.1f')\n    width_widget = widgets.FloatText(value=1.0, description=\"Peak range: ±\", layout=widgets.Layout(width='140px', margin='0 10px 0 0'), step=0.1, format='%.1f')\n    offset_widget = widgets.FloatText(value=1.0, description=\"Baseline: ±\", layout=widgets.Layout(width='140px', margin='0 10px 0 0'), step=0.05, format='%.1f')\n    range_width_widgets[label] = (center_widget, width_widget)\n    baseline_offset_widgets[label] = offset_widget\n\n# Action buttons\nfit_button = widgets.Button(description=\"Fit and Calculate Ratios\", layout=widgets.Layout(width='300px', height='30px'))\nsave_button = widgets.Button(description=\"Save Results\", layout=widgets.Layout(width='200px', height='30px'))\n\n# Assemble UI layout\nui = widgets.VBox([\n    upload_widget,\n    widgets.HBox([fit_model, symmetric_fit, use_baseline, baseline_type]),\n    widgets.HBox([smoothing_window, smoothing_poly]),\n    widgets.HBox([pixel_widget, frames_widget]),\n    widgets.HTML(\"<b>Edit Peak Centers and Ranges</b><br><i>Baseline estimated from model at center ± baseline m/z offset</i>\"),\n    *[widgets.HBox([range_width_widgets[label][0], range_width_widgets[label][1], baseline_offset_widgets[label]]) for label in region_labels],\n    widgets.HBox([fit_button, save_button])\n])\n\n# Global containers for outputs\nfig = None\ndf_summary = None\n\n# === Retrieve selected model from lmfit ===\ndef get_model(model_type, symmetric=True):\n    \"\"\"Return model instance based on user selection.\"\"\"\n    if model_type == 'gaussian':\n        return GaussianModel() if symmetric else (SkewedGaussianModel() if SkewedGaussianModel else GaussianModel())\n    elif model_type == 'lorentzian':\n        return LorentzianModel() if symmetric else VoigtModel()\n    elif model_type == 'pseudovoigt':\n        return PseudoVoigtModel() if symmetric else VoigtModel()\n    else:\n        raise ValueError(\"Unsupported model type\")\n\n# === Fit one peak region with baseline correction ===\ndef fit_peak_custom_baseline(x_all, y_all, model_type, mz_range, baseline_offset, symmetric, use_baseline, baseline_mode):\n    # x_all, y_all: full smoothed spectra arrays\n    # mz_range: user-selected m/z range for this peak\n\n    mask_peak = (x_all >= mz_range[0]) & (x_all <= mz_range[1])\n    x_peak = x_all[mask_peak]  # m/z values inside the peak window\n    y_peak = y_all[mask_peak]  # corresponding intensities\n\n    if len(x_peak) < 5:\n        raise ValueError(\"Peak range too narrow or no data points available.\")\n\n    model = get_model(model_type, symmetric=symmetric)  # initialize selected model\n\n    # === Estimate initial parameters ===\n    center_guess = (mz_range[0] + mz_range[1]) / 2  # midpoint of selected range\n    height_guess = np.max(y_peak)\n    sigma_guess = (mz_range[1] - mz_range[0]) / 4\n    amplitude_guess = height_guess * sigma_guess * np.sqrt(2 * np.pi)\n    params = model.make_params(center=center_guess, amplitude=amplitude_guess, sigma=sigma_guess)\n\n    # === Initial fit without baseline correction ===\n    initial_result = model.fit(y_peak, params, x=x_peak)  # returns ModelResult\n\n    # === Estimate baseline and subtract ===\n    if use_baseline:\n        if baseline_mode == 'average':\n            left_val = np.interp(center_guess - baseline_offset, x_peak, initial_result.best_fit)\n            right_val = np.interp(center_guess + baseline_offset, x_peak, initial_result.best_fit)\n            baseline = np.mean([left_val, right_val])\n            y_corr = y_peak - baseline\n        elif baseline_mode == 'linear':\n            center = (mz_range[0] + mz_range[1]) / 2\n            left_mask = (x_all >= center - baseline_offset) & (x_all < center - baseline_offset / 2)\n            right_mask = (x_all > center + baseline_offset / 2) & (x_all <= center + baseline_offset)\n            x_baseline = np.concatenate([x_all[left_mask], x_all[right_mask]])\n            y_baseline = np.concatenate([y_all[left_mask], y_all[right_mask]])\n            p = np.polyfit(x_baseline, y_baseline, deg=1)  # linear baseline fit\n            baseline_line = np.polyval(p, x_peak)  # evaluate baseline\n            y_corr = y_peak - baseline_line\n        elif baseline_mode == 'polynomial':\n            p = np.polyfit(x_peak, y_peak, deg=2)  # quadratic fit\n            baseline_line = np.polyval(p, x_peak)\n            y_corr = y_peak - baseline_line\n        else:\n            y_corr = y_peak\n    else:\n        y_corr = y_peak\n\n    # === Final model fit on baseline-corrected data ===\n    final_result = model.fit(y_corr, model.make_params(center=center_guess, amplitude=amplitude_guess, sigma=sigma_guess), x=x_peak)\n\n    # === Output results ===\n    area = final_result.params['amplitude'].value  # area under peak\n    residuals = y_corr - final_result.best_fit\n    ss_res = np.sum(residuals**2)  # sum of squared residuals\n    ss_tot = np.sum((y_corr - np.mean(y_corr))**2)\n    r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan  # fit quality\n\n    return final_result, x_peak, y_peak, y_corr, area, residuals, r_squared\n\ndef run_fitting(b):\n    global df_summary, fig, x, y\n    clear_output(wait=True)\n    display(ui)\n\n    if x is None or y is None:\n        print(\"Please upload a .txt file before running fitting.\")\n        return\n\n    if smoothing_window.value >= len(y):\n        print(\"Error: Smoothing window too large for data length.\")\n        return\n\n    y_smooth = savgol_filter(y, smoothing_window.value, smoothing_poly.value)\n\n    regions = {\n        label: (\n            range_width_widgets[label][0].value - range_width_widgets[label][1].value,\n            range_width_widgets[label][0].value + range_width_widgets[label][1].value\n        )\n        for label in region_labels\n    }\n    offsets = {label: baseline_offset_widgets[label].value for label in region_labels}\n    ratio_groups = [('235U', '238U'), ('235UO', '238UO'), ('235UO2', '238UO2')]\n\n    areas = {}\n    r2_values = {}\n    results = {}\n\n    fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n    axes = axes.flatten()\n\n    for i, label in enumerate(region_labels):\n        mz_range = regions[label]\n        baseline_offset = offsets[label]\n\n        try:\n            result, x_fit, y_fit, y_corr, area, residuals, r2 = fit_peak_custom_baseline(\n                x, y_smooth, fit_model.value, mz_range, baseline_offset, symmetric_fit.value, use_baseline.value, baseline_type.value\n            )\n        except Exception as e:\n            print(f\"Error fitting {label}: {e}\")\n            continue\n\n        areas[label] = area\n        r2_values[label] = r2\n        results[label] = result\n\n        ax = axes[i]\n        ax.plot(x_fit, y_fit, label='Smoothed', color='blue')\n        if use_baseline.value:\n            ax.plot(x_fit, y_corr, label='Corrected', color='purple')\n        ax.plot(x_fit, result.best_fit, 'r--', label='Fit')\n        ax.plot(x_fit, residuals, 'k:', label='Fitting deviation')\n        ax.set_title(f\"{label} (R² = {r2:.4f})\")\n        ax.legend()\n        ax.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\n    def calc_ratio(a1, a2):\n        return a1 / (a1 + a2) if (a1 + a2) > 0 else np.nan\n\n    summary_rows = []\n    model_name = fit_model.value.capitalize()\n\n    for label in region_labels:\n        area_val = areas.get(label, np.nan)\n        summary_rows.append({\n        \"Ions\": label,\n        \"Area\": area_val,\n        \"R²\": r2_values.get(label, np.nan),\n        \"235U Isotopic Ratio\": \"\"\n    })\n\n    for a1, a2 in ratio_groups:\n        r = calc_ratio(areas.get(a1, 0), areas.get(a2, 0))\n        for row in summary_rows:\n            if row[\"Ions\"] == a1:\n                row[\"235U Isotopic Ratio\"] = \"\" if pd.isna(r) else f\"{r:.4f}\"\n\n    df_summary = pd.DataFrame(summary_rows, columns=[\"Ions\", \"Area\", \"R²\", \"235U Isotopic Ratio\"])\n    pixel = pixel_widget.value\n    frames = frames_widget.value\n    df_summary.insert(1, \"Counts\", df_summary[\"Area\"] * frames * (pixel ** 2))\n    df_summary = df_summary.drop(columns=[\"Area\"])\n    df_summary.index = np.arange(1, len(df_summary) + 1)\n    display(df_summary)\n\ndef save_results(b):\n    global df_summary, fig\n    if df_summary is None or fig is None:\n        print(\"No results to save. Please run the fitting first.\")\n        return\n    base_name = os.path.splitext(os.path.basename(txt_file))[0] if txt_file else \"output\"\n    fig.savefig(f\"{base_name}_fit.png\", dpi=300)\n\n    # Prepare fitting metadata\n    settings = {\n        \"Fitting Model\": fit_model.value,\n        \"Symmetric Peak\": symmetric_fit.value,\n        \"Baseline Correction\": use_baseline.value,\n        \"Baseline Type\": baseline_type.value,\n        \"Smoothing Window\": smoothing_window.value,\n        \"Smoothing Polyorder\": smoothing_poly.value\n    }\n\n    # Construct metadata as header lines\n    header_lines = [\"Fitting Parameters Used:\"]\n    header_lines += [f\" {k}: {v}\" for k, v in settings.items()]\n    header_lines += [\n        f\" Pixel: {pixel_widget.value}\",\n        f\" Frames: {frames_widget.value}\"]\n\n    header_lines += [\"Peak Regions (m/z range):\"]\n    for label in region_labels:\n        center = range_width_widgets[label][0].value\n        width = range_width_widgets[label][1].value\n        offset = baseline_offset_widgets[label].value\n        header_lines.append(f\" {label}: center = {center}, ±range = {width}, ±baseline = {offset}\")\n\n    csv_path = f\"{base_name}_summary.csv\"\n    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n        df_summary.to_csv(f, index=False)  # Write the results table\n        f.write(\"\\n\")  # Blank line before metadata section\n\n    with open(csv_path, \"a\", encoding=\"utf-8\") as f:\n        for line in header_lines:\n                        f.write(line.strip() + \"\\n\")  # Each metadata line on a new row\n\n    print(f\"Saved: {base_name}_fit.png and {base_name}_summary.csv with fitting settings\")\n    print(f\"Saved: {base_name}_fit.png and {base_name}_summary.csv\")\n\n# === [EVENT BINDING] ===\nfit_button.on_click(run_fitting)\nsave_button.on_click(save_results)\n\n# === [UPLOAD EVENT HANDLER] ===\ndef handle_upload(change):\n    global data, x, y, txt_file\n    uploaded = upload_widget.value\n    if not uploaded:\n        print(\"No file uploaded.\")\n        return\n    file_info = list(uploaded.values())[0] if isinstance(uploaded, dict) else uploaded[0]\n    txt_file = file_info['name']\n    content = file_info['content']\n    try:\n        df = pd.read_csv(io.BytesIO(content), sep='\\t', comment='#')\n        df = df.dropna(subset=[x_column, y_column])\n        data = df\n        x = data[x_column].values\n        y = data[y_column].values\n        clear_output(wait=True)\n        display(ui)\n        print(f\"Loaded: {txt_file} | {len(data)} rows\")\n    except Exception as e:\n        print(f\"Failed to load file: {e}\")\n\nupload_widget.observe(handle_upload, names='value')\n\n# === [DISPLAY UI INITIALLY] ===\ndisplay(ui)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(FileUpload(value=(), accept='.txt', description='Upload .txt File', layout=Layout(width='300px'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fd7150214654d3baa71153e40764674"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 21
    },
    {
      "id": "1675a8bd-007f-4bf0-8d26-569052b3b33c",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}